# LAB3_Part2：决策树(Decision Tree)

> **课程**：人工智能与机器学习基础
> **作者**：TA：王珏
> **日期**：2025年11月

[toc]

---

## 环境配置

本指南将带你从零开始配置`jupyter notebook`实验环境，并成功运行 `decision_tree.ipynb`。

### 1. 激活 Conda 环境

```bash
conda activate ai25
```

### 2. 安装依赖（如果尚未安装）

前面的实验应该可以让你跳过这一步。如果没有，请运行：

```bash
pip install numpy pandas scikit-learn matplotlib
```

### 3. 安装并配置 Jupyter Notebook

与LAB1和LAB2不同，为展示决策树直观效果，并降低LAB3整体工作量，此次实验我们将使用 Jupyter Notebook 来完成实验。

终端运行：

```bash
pip install notebook ipykernel
python -m ipykernel install --user --name ai25 --display-name "Python (ai25)"
```

随后你可以选择运行：

```bash
jupyter notebook
```

这样你可以在浏览器中浏览和编辑 Notebook 文件。

> 注意到你需要在包含我们代码的目录下运行该命令。但不必须在同级目录下运行该命令，因为你可以在浏览器中导航到对应目录。

此外，你**也可以**选择在 VSCode 中打开 Notebook 文件（确保你已经安装了 VSCode 的 Jupyter 插件。）然后选择 Kernel 为 `Python (ai25)`。即可点开notebook后点击 Cell 旁边的运行按钮，逐步运行代码。

### 4. 项目结构

决策树部分应该至少包含以下文件：

```
LAB3/decision_tree
├── decision_tree.ipynb (你需要完成的实验代码文件)
├── decision_tree_setup.pdf （本文件）
└── public_tests.py
```

## 实验细节说明

### 关于实验代码

本次实验难度比较基础，主要考察你对决策树基本原理的理解和实现能力。请仔细阅读 `decision_tree.ipynb` 中的说明和要求，完成相应的代码实现。

在实验开头，助教展示了部分对数据集的预处理以及打印操作，希望可以启发大家如何去观测和理解数据，以便在训练时更好地使用数据集。

在每个Cell中，助教已经为你标注了需要实现的部分。同时也补充了大量的注释和提示，希望可以帮助你更好地理解和完成实验。

为了降低难度，同时让大家重点关注于基本原理和构建流程，决策树实验用到的数据集也非常简单，样本偏少且特征均为二值特征。

### 关于实验实现的多种方法

尽管如此，助教也鼓励大家尝试自行使用更复杂的数据集，也可以考虑任何我们上课时所提到的信息增益、信息增益率、基尼指数等特征选择方法，甚至可以尝试剪枝等方法来提升决策树的性能，避免过拟合等问题，从中体会到决策树的强大和灵活。

可以将以下思考加入到你的报告中，作为你的实验收获呈现：

* 决策树在处理二值特征时的优势和局限性
* 信息增益在特征选择中的作用
* 如果你使用了复杂的数据集，你有什么观察和发现？你的决策树会不会过拟合？你是如何尝试解决的？

## 提交

在本次实验中，你可以对 `decision_tree.ipynb` 进行任何你需要的修改和补充（但你需要在实验报告中提出）。完成实验后，本次代码和报告与之后的SVM、集成学习实验统一提交。

你需要提交的文件包括：

* `decision_tree.ipynb`：包含你完成的代码和实验结果。
* 实验报告：
  * 内容上需要包括：
    * 代码补全情况说明
    * 如果你简单补充并且正确运行了我们的`decision_tree.ipynb`，请基本讲清楚你的结果，并根据实验过程概括decision tree的基本原理。
    * 如果你尝试了更复杂的数据集或者在计算增益时用了不同的方法，请重点描述你的思考和实验过程。

> 谢谢大家！祝大家机器学习之旅愉快！
